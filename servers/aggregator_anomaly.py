import flwr as fl
import torch
import argparse
from typing import Dict, List
from collections import OrderedDict
from torch.utils.data import DataLoader
import numpy as np
import time
import json
import os
import sys
import psutil

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.model_anomaly import AnomalyDetectionCNN, SimpleAnomalyDetector
from core.dataset_anomaly import load_anomaly_data
from core.utils_anomaly import get_parameters, set_parameters

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Argumentos
parser = argparse.ArgumentParser(description="Agregador Hier√°rquico")
parser.add_argument("--port", type=int, required=True, help="Porta do agregador")
parser.add_argument("--server-ip", type=str, default="127.0.0.1:8080", help="IP do servidor global")
parser.add_argument("--min-clients", type=int, default=2, help="M√≠nimo de clientes")
parser.add_argument("--dataset", type=str, default="CIFAR10")
parser.add_argument("--use-transfer-learning", type=bool, default=True)
parser.add_argument("--seed", type=int, default=42)
args = parser.parse_args()

torch.manual_seed(args.seed)
aggregator_address = f"0.0.0.0:{args.port}"
final_parameters = None

aggregator_metrics = {
    "local_rounds": [],
    "communications": [],
    "accuracies": []
}

class CustomFedAvg(fl.server.strategy.FedAvg):
    def aggregate_fit(self, server_round, results, failures):
        global final_parameters
        start_time = time.time()
        
        aggregated_parameters, metrics = super().aggregate_fit(server_round, results, failures)
        
        if aggregated_parameters is not None:
            final_parameters = aggregated_parameters
            
            round_metrics = {
                "round": server_round,
                "clients_participated": len(results),
                "aggregation_time": time.time() - start_time,
            }
            aggregator_metrics["local_rounds"].append(round_metrics)
            
        return aggregated_parameters, metrics

print(f"üè¢ Agregador: Iniciando em {aggregator_address}")
print(f"üë• Aguardando {args.min_clients} clientes...")

# ‚úÖ CORRE√á√ÉO: Estrat√©gia completa
strategy = CustomFedAvg(
    fraction_fit=1.0,
    min_fit_clients=args.min_clients,
    min_available_clients=args.min_clients,
    fraction_evaluate=1.0,
    min_evaluate_clients=args.min_clients
)

# Servidor local
try:
    fl.server.start_server(
        server_address=aggregator_address,
        config=fl.server.ServerConfig(num_rounds=3),
        strategy=strategy,
    )
except Exception as e:
    print(f"‚ùå Erro no agregador: {e}")
    exit(1)

print(f"‚úÖ Agrega√ß√£o local finalizada. Conectando ao servidor {args.server_ip}...")

# Prepara modelo para avalia√ß√£o
_, test_dataset, ModelClass, model_config = load_anomaly_data(
    args.dataset, num_clients=1, normal_class=0,
    use_transfer_learning=args.use_transfer_learning
)
test_loader = DataLoader(test_dataset, batch_size=32)
model = ModelClass(**model_config).to(DEVICE)

class AggregatorClient(fl.client.NumPyClient):
    def get_parameters(self, config):
        print(f"üè¢ Agregador: Enviando modelo para servidor")
        
        # ‚úÖ CORRE√á√ÉO CR√çTICA: Verificar se final_parameters √© v√°lido
        if final_parameters is not None and hasattr(final_parameters, 'tensors'):
            try:
                # Converter objeto Parameters para lista de numpy arrays
                parameters_ndarrays = fl.common.parameters_to_ndarrays(final_parameters)
                print(f"‚úÖ Agregador: {len(parameters_ndarrays)} par√¢metros convertidos")
                return parameters_ndarrays
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao converter final_parameters: {e}")
                # Fallback: usar par√¢metros do modelo
                return get_parameters(model)
        else:
            # Retorna par√¢metros iniciais do modelo se n√£o houve agrega√ß√£o
            print("‚ö†Ô∏è  Agregador: Usando par√¢metros iniciais do modelo")
            return get_parameters(model)

    def fit(self, parameters, config):
        # ‚úÖ CORRE√á√ÉO: Garantir que retorna numpy arrays
        return self.get_parameters(config), 1, {}

    def evaluate(self, parameters: List[np.ndarray], config: Dict[str, str]):
        start_time = time.time()
        print(f"üè¢ Agregador: Avaliando modelo...")
        
        set_parameters(model, parameters)
        model.eval()

        if isinstance(model, SimpleAnomalyDetector):
            criterion = torch.nn.CrossEntropyLoss()
        else:
            criterion = torch.nn.MSELoss()

        total_loss = 0.0
        correct_anomalies = 0
        total_samples = 0
        
        with torch.no_grad():
            for images, labels, is_anomaly in test_loader:
                images, is_anomaly = images.to(DEVICE), is_anomaly.to(DEVICE)
                
                if isinstance(model, SimpleAnomalyDetector):
                    outputs = model(images)
                    loss = criterion(outputs, is_anomaly)
                    _, predicted = torch.max(outputs, 1)
                    correct_anomalies += (predicted == is_anomaly).sum().item()
                else:
                    _, reconstructions = model(images)
                    loss = criterion(reconstructions, images)
                    anomaly_scores = torch.mean(torch.pow(reconstructions - images, 2), dim=[1,2,3])
                    predicted_anomalies = (anomaly_scores > 0.1).float()
                    correct_anomalies += (predicted_anomalies == is_anomaly).sum().item()
                
                total_loss += loss.item() * images.size(0)
                total_samples += images.size(0)

        accuracy = correct_anomalies / total_samples if total_samples > 0 else 0
        avg_loss = total_loss / total_samples if total_samples > 0 else float('inf')
        eval_time = time.time() - start_time
        
        # Registra comunica√ß√£o
        comm_event = {
            "accuracy": accuracy,
            "eval_time": eval_time,
        }
        aggregator_metrics["communications"].append(comm_event)
        aggregator_metrics["accuracies"].append(accuracy)
        
        print(f"üè¢ Agregador: Loss: {avg_loss:.4f}, Acc: {accuracy:.4f}")
        
        # Monitoramento de mem√≥ria
        process = psutil.Process(os.getpid())
        mem_info = process.memory_info()
        print(f"üìä Agregador: Uso de mem√≥ria: {mem_info.rss / (1024 * 1024):.2f} MB (RSS), {mem_info.vms / (1024 * 1024):.2f} MB (VMS)")
        return avg_loss, total_samples, {"accuracy": accuracy}

# Conecta ao servidor
try:
    fl.client.start_client(
        server_address=args.server_ip,
        client=AggregatorClient().to_client(),
    )
    
    # Salva m√©tricas
    os.makedirs("results", exist_ok=True)
    metrics_file = f"results/aggregator_port_{args.port}_metrics.json"
    with open(metrics_file, "w") as f:
        json.dump(aggregator_metrics, f, indent=2)
    print(f"üíæ M√©tricas salvas: {metrics_file}")
    
except Exception as e:
    print(f"‚ùå Erro ao conectar com servidor: {e}")